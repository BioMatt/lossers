{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e5c10a76-09f2-431a-b169-4e56e5664dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Core libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "\n",
    "# Transformers and PEFT\n",
    "from transformers import AutoTokenizer, AutoModel, BertConfig\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "# Data processing and visualization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Utilities\n",
    "import gc\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Set style for prettier plots\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "print(\"âœ“ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31316e20-81b0-4ff5-96b2-5a4eb126aa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = BertConfig.from_pretrained(\"zhihan1996/DNABERT-2-117M\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"zhihan1996/DNABERT-2-117M\", trust_remote_code=True)\n",
    "model = AutoModel.from_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8e9973e8-123c-40e5-8542-012ed602fb3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                       genus       species  \\\n",
       "0               Alitibacter   langaaensis   \n",
       "1               Alitibacter   langaaensis   \n",
       "2               Roseovarius     maritimus   \n",
       "3               Roseovarius        roseus   \n",
       "4           Planosporangium      spinosum   \n",
       "...                     ...           ...   \n",
       "27727     Thermoclostridium  stercorarium   \n",
       "27728           Clostridium      isatidis   \n",
       "27729         Couchioplanes     caeruleus   \n",
       "27730             Halomonas     koreensis   \n",
       "27731  Pseudoflavonifractor   phocaeensis   \n",
       "\n",
       "                                                sequence   identifier  \\\n",
       "0      ATTGAAGAGTTTGATCATGGCTCAGATTGAACGCTGGCGGCAGGCT...  NR_118751.1   \n",
       "1      ATTGAACGCTGGCGGCAGGCTTAACACATGCAAGTCGAACGGTAAC...  NR_042885.1   \n",
       "2      CAACTTGAGAGTTTGATCCTGGCTCAGAACGAACGCTGGCGGCAGG...  NR_200035.1   \n",
       "3      CAACTTGAGAGTTTGATCCTGGCTCAGAACGAACGCTGGCGGCAGG...  NR_200034.1   \n",
       "4      TTGTTGGAGAGTTTGATCCTGGCTCAGGACGAACGCTGGCGGCGTG...  NR_200033.1   \n",
       "...                                                  ...          ...   \n",
       "27727  TGATCCTGGCTCAGGACGAACGCTGGCGGCGTGCCTAACACATGCA...  NR_025100.1   \n",
       "27728  GGCGTGCNTAACACATGCAAGTCGAGCGAGGTGATTTCNTTCGGGA...  NR_026347.1   \n",
       "27729  CGCTGGCGGCGTGCTTAACACATGCAAGTCGAGCGGAAAGGCCCCT...  NR_026295.1   \n",
       "27730  ACGATGGGAGCTTGCTCCCAGGCGTCGAGCGGCGGACGGGTGAGTA...  NR_025773.1   \n",
       "27731  AGAGTTTGATCCTGGCTCAGGATGAACGCTGGCGGCGTRCTTAACA...  NR_147370.1   \n",
       "\n",
       "             is_complete  \n",
       "0       partial sequence  \n",
       "1       partial sequence  \n",
       "2      complete sequence  \n",
       "3      complete sequence  \n",
       "4      complete sequence  \n",
       "...                  ...  \n",
       "27727   partial sequence  \n",
       "27728   partial sequence  \n",
       "27729   partial sequence  \n",
       "27730   partial sequence  \n",
       "27731   partial sequence  \n",
       "\n",
       "[27732 rows x 5 columns]>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the new sequence data and run head to see the overall data structure\n",
    "data_in = pd.read_csv(\"data/sequence-wide.tsv\", sep='\\t') \n",
    "data_in.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cb1efdce-56aa-428f-a633-b6d28c915dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 1:\n",
      "0                 Alitibacter\n",
      "1                 Alitibacter\n",
      "2                 Roseovarius\n",
      "3                 Roseovarius\n",
      "4             Planosporangium\n",
      "                 ...         \n",
      "27727       Thermoclostridium\n",
      "27728             Clostridium\n",
      "27729           Couchioplanes\n",
      "27730               Halomonas\n",
      "27731    Pseudoflavonifractor\n",
      "Name: genus, Length: 27732, dtype: object\n",
      "Column 2:\n",
      "0         langaaensis\n",
      "1         langaaensis\n",
      "2           maritimus\n",
      "3              roseus\n",
      "4            spinosum\n",
      "             ...     \n",
      "27727    stercorarium\n",
      "27728        isatidis\n",
      "27729       caeruleus\n",
      "27730       koreensis\n",
      "27731     phocaeensis\n",
      "Name: species, Length: 27732, dtype: object\n",
      "Column 3:\n",
      "0        ATTGAAGAGTTTGATCATGGCTCAGATTGAACGCTGGCGGCAGGCT...\n",
      "1        ATTGAACGCTGGCGGCAGGCTTAACACATGCAAGTCGAACGGTAAC...\n",
      "2        CAACTTGAGAGTTTGATCCTGGCTCAGAACGAACGCTGGCGGCAGG...\n",
      "3        CAACTTGAGAGTTTGATCCTGGCTCAGAACGAACGCTGGCGGCAGG...\n",
      "4        TTGTTGGAGAGTTTGATCCTGGCTCAGGACGAACGCTGGCGGCGTG...\n",
      "                               ...                        \n",
      "27727    TGATCCTGGCTCAGGACGAACGCTGGCGGCGTGCCTAACACATGCA...\n",
      "27728    GGCGTGCNTAACACATGCAAGTCGAGCGAGGTGATTTCNTTCGGGA...\n",
      "27729    CGCTGGCGGCGTGCTTAACACATGCAAGTCGAGCGGAAAGGCCCCT...\n",
      "27730    ACGATGGGAGCTTGCTCCCAGGCGTCGAGCGGCGGACGGGTGAGTA...\n",
      "27731    AGAGTTTGATCCTGGCTCAGGATGAACGCTGGCGGCGTRCTTAACA...\n",
      "Name: sequence, Length: 27732, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check the columns\n",
    "print(\"Column 1:\")\n",
    "print(data_in.iloc[:, 0])\n",
    "print(\"Column 2:\")\n",
    "print(data_in.iloc[:, 1])\n",
    "print(\"Column 3:\")\n",
    "print(data_in.iloc[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "90b6a90c-5dc6-4402-b207-c4ec3f1647b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        ATTGAAGAGTTTGATCATGGCTCAGATTGAACGCTGGCGGCAGGCT...\n",
       "1        ATTGAACGCTGGCGGCAGGCTTAACACATGCAAGTCGAACGGTAAC...\n",
       "2        CAACTTGAGAGTTTGATCCTGGCTCAGAACGAACGCTGGCGGCAGG...\n",
       "3        CAACTTGAGAGTTTGATCCTGGCTCAGAACGAACGCTGGCGGCAGG...\n",
       "4        TTGTTGGAGAGTTTGATCCTGGCTCAGGACGAACGCTGGCGGCGTG...\n",
       "                               ...                        \n",
       "27727    TGATCCTGGCTCAGGACGAACGCTGGCGGCGTGCCTAACACATGCA...\n",
       "27728    GGCGTGCNTAACACATGCAAGTCGAGCGAGGTGATTTCNTTCGGGA...\n",
       "27729    CGCTGGCGGCGTGCTTAACACATGCAAGTCGAGCGGAAAGGCCCCT...\n",
       "27730    ACGATGGGAGCTTGCTCCCAGGCGTCGAGCGGCGGACGGGTGAGTA...\n",
       "27731    AGAGTTTGATCCTGGCTCAGGATGAACGCTGGCGGCGTRCTTAACA...\n",
       "Name: sequence, Length: 27732, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_in.sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "71b93154-30bd-411a-a82b-e6dd4026314b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2061, 25, 222, 23, 224, 143, 3411, 403, 247, 53, 150, 527, 2759, 2834, 2734, 724, 873, 81, 118, 2470, 30, 708, 72, 61, 679, 29, 200, 88, 2894, 71, 117, 639, 72, 1478, 315, 137, 2787, 825, 1826, 966, 189, 1235, 45, 229, 4079, 314, 1340, 835, 427, 138, 316, 99, 120, 2139, 76, 36, 987, 75, 315, 8, 0, 41, 199, 0, 0, 5, 778, 460, 632, 59, 100, 72, 26, 0, 1212, 1527, 71, 148, 281, 0, 9, 3558, 238, 92, 635, 59, 111, 556, 2787, 135, 52, 259, 64, 72, 31, 120, 469, 2816, 50, 2638, 166, 29, 135, 1262, 31, 141, 17, 495, 1170, 317, 32, 443, 79, 78, 30, 619, 36, 247, 137, 1517, 2810, 19, 153, 1826, 20, 277, 1080, 332, 159, 15, 583, 458, 61, 783, 18, 486, 17, 540, 29, 200, 14, 183, 22, 236, 168, 37, 282, 3453, 71, 7, 0, 3386, 34, 123, 315, 103, 265, 194, 50, 42, 534, 171, 259, 166, 112, 2394, 200, 106, 59, 118, 1952, 409, 577, 117, 124, 1832, 0, 113, 205, 35, 553, 403, 38, 499, 16, 605, 788, 212, 8, 0, 0, 9, 3382, 169, 194, 233, 368, 38, 2785, 1149, 282, 1435, 66, 101, 39, 386, 8, 0, 9, 10, 846, 599, 159, 27, 1317, 208, 3928, 109, 499, 0, 9, 118, 317, 292, 114, 149, 100, 462, 2093, 2641, 14, 163, 2117, 72, 212, 126, 823, 472, 65, 62, 1440, 239, 163, 327, 48, 342, 0, 5, 90, 547, 93, 1818, 1128, 130, 48, 89, 266, 8, 0, 9, 1731, 386, 33, 251, 1957, 8, 0, 9, 438, 57, 885, 245, 1191, 67, 224, 3953, 93, 522, 3315, 123, 37, 238, 30, 104, 2276, 247, 166, 74, 393, 61, 841, 116, 3345, 278, 35, 90, 216, 33, 220, 2485, 3770, 52, 41, 57, 2957, 68, 16, 124, 455, 48, 247, 1092, 134, 716, 184, 2146, 1002, 397, 2596, 824, 101, 35, 637, 3642, 540, 347, 165, 764, 268, 72, 252, 115, 8, 2]\n"
     ]
    }
   ],
   "source": [
    "# Convert the new sequences to input tokens, view the first element\n",
    "inputs = tokenizer(data_in.sequence.to_list())[\"input_ids\"]\n",
    "print(inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bb5d480c-bc7c-4a53-af57-4f096a1deedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Random seeds set for reproducibility\n"
     ]
    }
   ],
   "source": [
    "# Set all random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"âœ“ Random seeds set for reproducibility\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3148d170-34b8-472b-b413-96254b368c0e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LoraConfig' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     14\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Trainable: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainable_pct\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m%\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Configure LoRA\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m lora_config = \u001b[43mLoraConfig\u001b[49m(\n\u001b[32m     18\u001b[39m     r=\u001b[32m8\u001b[39m,                              \u001b[38;5;66;03m# Rank (lower = fewer params)\u001b[39;00m\n\u001b[32m     19\u001b[39m     lora_alpha=\u001b[32m32\u001b[39m,                    \u001b[38;5;66;03m# Scaling factor\u001b[39;00m\n\u001b[32m     20\u001b[39m     target_modules=[\u001b[33m\"\u001b[39m\u001b[33mquery\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mvalue\u001b[39m\u001b[33m\"\u001b[39m], \u001b[38;5;66;03m# Adapt attention layers\u001b[39;00m\n\u001b[32m     21\u001b[39m     lora_dropout=\u001b[32m0.1\u001b[39m,                 \u001b[38;5;66;03m# Regularization\u001b[39;00m\n\u001b[32m     22\u001b[39m     bias=\u001b[33m\"\u001b[39m\u001b[33mnone\u001b[39m\u001b[33m\"\u001b[39m,                      \u001b[38;5;66;03m# Don't adapt bias terms\u001b[39;00m\n\u001b[32m     23\u001b[39m )\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Apply LoRA to the model\u001b[39;00m\n\u001b[32m     26\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mðŸ”„ Applying LoRA adapters to model...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'LoraConfig' is not defined"
     ]
    }
   ],
   "source": [
    "# Helper function to count trainable parameters\n",
    "def print_trainable_parameters(model):\n",
    "    \"\"\"Count and display trainable vs total parameters.\"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    \n",
    "    trainable_pct = 100 * trainable_params / all_param\n",
    "    print(f\"  Trainable params: {trainable_params:,}\")\n",
    "    print(f\"  Total params: {all_param:,}\")\n",
    "    print(f\"  Trainable: {trainable_pct:.2f}%\")\n",
    "\n",
    "# Configure LoRA\n",
    "lora_config = LoraConfig(\n",
    "    r=8,                              # Rank (lower = fewer params)\n",
    "    lora_alpha=32,                    # Scaling factor\n",
    "    target_modules=[\"query\", \"value\"], # Adapt attention layers\n",
    "    lora_dropout=0.1,                 # Regularization\n",
    "    bias=\"none\",                      # Don't adapt bias terms\n",
    ")\n",
    "\n",
    "# Apply LoRA to the model\n",
    "print(\"ðŸ”„ Applying LoRA adapters to model...\\n\")\n",
    "ft_model = get_peft_model(model, lora_config)\n",
    "\n",
    "print(\"ðŸ“Š Model Parameters Comparison:\")\n",
    "print(\"-\" * 60)\n",
    "print(\"Before LoRA (original model):\")\n",
    "print_trainable_parameters(AutoModel.from_pretrained(MODEL_CHECKPOINT))\n",
    "print(\"\\nAfter LoRA (adapted model):\")\n",
    "print_trainable_parameters(ft_model)\n",
    "print(\"-\" * 60)\n",
    "print(\"\\nâœ“ LoRA adapters applied successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41550961-a025-459e-ba55-7968fd773184",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
