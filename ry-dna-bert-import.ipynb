{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "903dd0b8-43d0-4343-9807-99e0502f43a9",
   "metadata": {},
   "source": [
    "## üì¶ Step 1: Setup and Imports\n",
    "\n",
    "We'll use:\n",
    "- **`transformers`**: Load pre-trained ESM models from Hugging Face\n",
    "- **`peft`**: Apply LoRA adapters for parameter-efficient fine-tuning\n",
    "- **`torch`**: Deep learning framework for training\n",
    "- **`scikit-learn`**: Metrics and baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5c10a76-09f2-431a-b169-4e56e5664dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel, BertConfig\n",
    "\n",
    "# Data processing and visualization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "print(\"‚úì All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78daa735-fba9-4685-8106-f5b5dadc3556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Using device: cuda\n",
      "  GPU: NVIDIA A100-SXM4-40GB\n",
      "  Memory: 42.29 GB\n"
     ]
    }
   ],
   "source": [
    "# Configure compute device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"‚úì Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"  GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"  Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cbbbc6-2c63-4133-adfd-41f092db0a06",
   "metadata": {},
   "source": [
    "## ü§ñ Step 2: Load Pre-trained DNABERT-2 Model\n",
    "\n",
    "We'll use the DNABERT-2 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e9973e8-123c-40e5-8542-012ed602fb3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Loading model: zhihan1996/DNABERT-2-117M\n",
      "‚úì Model loaded successfully!\n",
      "  Total parameters: 89.2 million\n",
      "  Hidden size: 768\n",
      "  Number of layers: 12\n"
     ]
    }
   ],
   "source": [
    "# Select model checkpoint (change this to experiment with different sizes)\n",
    "MODEL_CHECKPOINT = \"zhihan1996/DNABERT-2-117M\"\n",
    "\n",
    "config = BertConfig.from_pretrained(MODEL_CHECKPOINT)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT, trust_remote_code=True)\n",
    "\n",
    "print(f\"üì• Loading model: {MODEL_CHECKPOINT}\")\n",
    "model = AutoModel.from_config(config)\n",
    "model.eval()  # Set to evaluation mode (no training yet)\n",
    "\n",
    "# Calculate total parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"‚úì Model loaded successfully!\")\n",
    "print(f\"  Total parameters: {total_params/1e6:.1f} million\")\n",
    "print(f\"  Hidden size: {model.config.hidden_size}\")\n",
    "print(f\"  Number of layers: {model.config.num_hidden_layers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f86edafc-cf8f-4e0f-a6f9-1dc610369c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Tokenizer loaded!\n",
      "  Vocabulary size: 4096\n",
      "\n",
      "üìñ First 10 keys in Tokenizer vocabulary:\n",
      "TATTTA\n",
      "GGTTATT\n",
      "GTGATT\n",
      "CACATTTT\n",
      "GAATATA\n",
      "CTTCAAA\n",
      "CCAAGG\n",
      "TATTTATTTT\n",
      "GTCGTG\n",
      "TCCCCAA\n"
     ]
    }
   ],
   "source": [
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT, trust_remote_code=True)\n",
    "\n",
    "print(\"‚úì Tokenizer loaded!\")\n",
    "print(f\"  Vocabulary size: {len(tokenizer)}\")\n",
    "print(\"\\nüìñ First 10 keys in Tokenizer vocabulary:\")\n",
    "# print(tokenizer.get_vocab())\n",
    "\n",
    "for x in list(tokenizer.get_vocab())[0:10]:\n",
    "    print (x)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ae66fa5c-893e-47d6-a8ae-60a2c602d9bf",
   "metadata": {},
   "source": [
    "dna = \"ACGTAGCATCGGATCTATCTATCGACACTTGGTTATCGATCTACGAGCATCTCGTTAGC\"\n",
    "inputs = tokenizer(dna, return_tensors = 'pt')[\"input_ids\"]\n",
    "hidden_states = model(inputs)[0] # [1, sequence_length, 768]\n",
    "\n",
    "# embedding with mean pooling\n",
    "embedding_mean = torch.mean(hidden_states[0], dim=0)\n",
    "print(embedding_mean.shape) # expect to be 768\n",
    "\n",
    "# embedding with max pooling\n",
    "embedding_max = torch.max(hidden_states[0], dim=0)[0]\n",
    "print(embedding_max.shape) # expect to be 768"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cb8e7c-4dad-4641-be1c-767b21bd9dfc",
   "metadata": {},
   "source": [
    "## Step 3: Load and Prepare Dataset\n",
    "\n",
    "Load sequence data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c46dc80-0d8c-4b5b-80c8-692cefb439a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading dataset: data/sequence-wide.tsv\n",
      "‚úì Dataset loaded successfully!\n",
      "  Total samples: 27,732\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genus</th>\n",
       "      <th>species</th>\n",
       "      <th>sequence</th>\n",
       "      <th>identifier</th>\n",
       "      <th>is_complete</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alitibacter</td>\n",
       "      <td>langaaensis</td>\n",
       "      <td>ATTGAAGAGTTTGATCATGGCTCAGATTGAACGCTGGCGGCAGGCT...</td>\n",
       "      <td>NR_118751.1</td>\n",
       "      <td>partial sequence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alitibacter</td>\n",
       "      <td>langaaensis</td>\n",
       "      <td>ATTGAACGCTGGCGGCAGGCTTAACACATGCAAGTCGAACGGTAAC...</td>\n",
       "      <td>NR_042885.1</td>\n",
       "      <td>partial sequence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Roseovarius</td>\n",
       "      <td>maritimus</td>\n",
       "      <td>CAACTTGAGAGTTTGATCCTGGCTCAGAACGAACGCTGGCGGCAGG...</td>\n",
       "      <td>NR_200035.1</td>\n",
       "      <td>complete sequence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Roseovarius</td>\n",
       "      <td>roseus</td>\n",
       "      <td>CAACTTGAGAGTTTGATCCTGGCTCAGAACGAACGCTGGCGGCAGG...</td>\n",
       "      <td>NR_200034.1</td>\n",
       "      <td>complete sequence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Planosporangium</td>\n",
       "      <td>spinosum</td>\n",
       "      <td>TTGTTGGAGAGTTTGATCCTGGCTCAGGACGAACGCTGGCGGCGTG...</td>\n",
       "      <td>NR_200033.1</td>\n",
       "      <td>complete sequence</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             genus      species  \\\n",
       "0      Alitibacter  langaaensis   \n",
       "1      Alitibacter  langaaensis   \n",
       "2      Roseovarius    maritimus   \n",
       "3      Roseovarius       roseus   \n",
       "4  Planosporangium     spinosum   \n",
       "\n",
       "                                            sequence   identifier  \\\n",
       "0  ATTGAAGAGTTTGATCATGGCTCAGATTGAACGCTGGCGGCAGGCT...  NR_118751.1   \n",
       "1  ATTGAACGCTGGCGGCAGGCTTAACACATGCAAGTCGAACGGTAAC...  NR_042885.1   \n",
       "2  CAACTTGAGAGTTTGATCCTGGCTCAGAACGAACGCTGGCGGCAGG...  NR_200035.1   \n",
       "3  CAACTTGAGAGTTTGATCCTGGCTCAGAACGAACGCTGGCGGCAGG...  NR_200034.1   \n",
       "4  TTGTTGGAGAGTTTGATCCTGGCTCAGGACGAACGCTGGCGGCGTG...  NR_200033.1   \n",
       "\n",
       "         is_complete  \n",
       "0   partial sequence  \n",
       "1   partial sequence  \n",
       "2  complete sequence  \n",
       "3  complete sequence  \n",
       "4  complete sequence  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the cleaned dataset\n",
    "DATASET_NAME = \"data/sequence-wide.tsv\"\n",
    "\n",
    "print(f\"üìÇ Loading dataset: {DATASET_NAME}\")\n",
    "dataset = pd.read_csv(DATASET_NAME, sep='\\t')\n",
    "\n",
    "print(f\"‚úì Dataset loaded successfully!\")\n",
    "print(f\"  Total samples: {len(dataset):,}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8a5e68-255c-4f10-bfb3-2d520c1d5ef2",
   "metadata": {},
   "source": [
    "## Step 4: Tokenization Example\n",
    "\n",
    "Let's tokenize a sample sequence to see the tokenizer in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0781e26a-a6cc-4896-9329-c8a163dff15d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample sequence (first row of dataset):\n",
      "  Identifier: NR_118751.1\n",
      "  Length: 1477 amino acids\n",
      "  Sequence: ATTGAAGAGTTTGATCATGGCTCAGATTGAACGCTGGCGGCAGGCTTAAC...\n"
     ]
    }
   ],
   "source": [
    "# Sample protein sequence: Alitibacter langaaensis NR_118751.1\n",
    "sequence = dataset[\"sequence\"][0]\n",
    "\n",
    "print(\"Sample sequence (first row of dataset):\")\n",
    "print(f\"  Identifier: {dataset[\"identifier\"][0]}\")\n",
    "print(f\"  Length: {len(sequence)} amino acids\")\n",
    "print(f\"  Sequence: {sequence[:50]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db7295aa-908c-4791-b41c-b65fcf24d588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Sequence tokenized!\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the sequence\n",
    "inputs = tokenizer(sequence, return_tensors=\"pt\").to(device)\n",
    "\n",
    "print(\"‚úì Sequence tokenized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca54f1c8-eedb-41b9-846a-9cc46cb9ea51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sequence length: 1477 amino acids\n",
      "Tokenized input IDs shape: torch.Size([1, 335])\n",
      "Token IDs: tensor([   1, 2061,   25,  222,   23,  224,  143, 3411,  403,  247,   53,  150,\n",
      "         527, 2759, 2834, 2734,  724,  873,   81,  118], device='cuda:0')...\n",
      "\n",
      "üí° Why is tokenized length different?\n",
      "   The tokenizer adds special tokens like <cls> (start) and <eos> (end)!\n"
     ]
    }
   ],
   "source": [
    "# Examine tokenized output\n",
    "print(f\"Original sequence length: {len(sequence)} amino acids\")\n",
    "print(f\"Tokenized input IDs shape: {inputs['input_ids'].shape}\")\n",
    "print(f\"Token IDs: {inputs['input_ids'][0][:20]}...\")  # Show first 20 tokens\n",
    "\n",
    "print(f\"\\nüí° Why is tokenized length different?\")\n",
    "print(f\"   The tokenizer adds special tokens like <cls> (start) and <eos> (end)!\")\n",
    "\n",
    "### DNABERT-2 also uses BPE tokenization, not single amino acids but groups of variable length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6246a49f-9668-4618-93f5-a4d6a130c99b",
   "metadata": {},
   "source": [
    "## üéØ Step 5: Zero-Shot Prediction\n",
    "\n",
    "The model was trained on masked language modeling (predicting missing amino acids), but the embeddings can be used **directly** for downstream tasks without additional training. This is called **zero-shot learning**.\n",
    "\n",
    "**Use case**: Find proteins similar in function or structure based on embedding similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6a63ebc-204b-42ef-bef0-3ad1f5d86c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Reference database created with 3 sequences\n"
     ]
    }
   ],
   "source": [
    "# Reference database of known microbes with different genus/species\n",
    "reference = {\n",
    "    \"Alitibacter langaaensis (NR_118751.1)\": \n",
    "        dataset[\"sequence\"][0],\n",
    "    \n",
    "    \"Alitibacter langaaensis (NR_042885.1)\": \n",
    "        dataset[\"sequence\"][1],\n",
    "    \n",
    "    \"Roseovarius maritimus (NR_200035.1)\": \n",
    "        dataset[\"sequence\"][2]\n",
    "}\n",
    "\n",
    "print(f\"‚úì Reference database created with {len(reference)} sequences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1402858-4e71-43e1-bdd5-26c6a3c940ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Query protein: Roseovarius roseus (NR_200034.1)\n"
     ]
    }
   ],
   "source": [
    "# Query microbe - which reference microbe is it most similar to?\n",
    "query = {\n",
    "    \"Roseovarius roseus (NR_200034.1)\": \n",
    "        dataset[\"sequence\"][3]\n",
    "}\n",
    "\n",
    "print(f\"üîç Query protein: {list(query.keys())[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5cf0ccb-0b36-4dd8-a680-1b85ee026858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Generating embeddings for reference database...\n",
      "‚úì Generated 3 reference embeddings\n",
      "\n",
      "üîÑ Generating embedding for query: Roseovarius roseus (NR_200034.1)...\n",
      "‚úì Query embedding generated\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings for reference database\n",
    "print(\"üîÑ Generating embeddings for reference database...\")\n",
    "reference_embeddings = {}\n",
    "with torch.no_grad():\n",
    "    for name, seq in reference.items():\n",
    "        ref_inputs = tokenizer(seq, return_tensors=\"pt\")[\"input_ids\"]\n",
    "        ref_outputs = model(ref_inputs)[0]\n",
    "        reference_embeddings[name] = torch.mean(ref_outputs[0], dim=0).numpy().reshape(1,-1)\n",
    "print(f\"‚úì Generated {len(reference_embeddings)} reference embeddings\")\n",
    "\n",
    "# Generate embedding for query protein\n",
    "query_name, query_sequence = next(iter(query.items()))\n",
    "print(f\"\\nüîÑ Generating embedding for query: {query_name}...\")\n",
    "with torch.no_grad():\n",
    "    query_inputs = tokenizer(query_sequence, return_tensors=\"pt\")[\"input_ids\"]\n",
    "    query_outputs = model(query_inputs)[0]\n",
    "    query_embedding = torch.mean(query_outputs[0], dim=0).numpy().reshape(1,-1)\n",
    "print(\"‚úì Query embedding generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4030c409-7018-4619-8aad-0c2f224de8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üîç ZERO-SHOT SIMILARITY SEARCH RESULTS\n",
      "======================================================================\n",
      "\n",
      "Query Microbe: Roseovarius roseus (NR_200034.1)\n",
      "\n",
      "Similarity Scores (sorted by relevance):\n",
      "----------------------------------------------------------------------\n",
      "Roseovarius maritimus (NR_200035.1)           0.9998 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "Alitibacter langaaensis (NR_042885.1)         0.9977 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "Alitibacter langaaensis (NR_118751.1)         0.9977 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "======================================================================\n",
      "üéØ Best Match: Roseovarius maritimus (NR_200035.1)\n",
      "   Similarity: 0.9998\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Calculate cosine similarity between query and each reference\n",
    "similarities = {}\n",
    "for name, ref_emb in reference_embeddings.items():\n",
    "    similarity = cosine_similarity(query_embedding, ref_emb)[0][0]\n",
    "    similarities[name] = similarity\n",
    "\n",
    "# Find best match\n",
    "best_match = max(similarities, key=similarities.get)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(f\"üîç ZERO-SHOT SIMILARITY SEARCH RESULTS\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nQuery Microbe: {query_name}\\n\")\n",
    "print(\"Similarity Scores (sorted by relevance):\")\n",
    "print(\"-\" * 70)\n",
    "for name, score in sorted(similarities.items(), key=lambda item: item[1], reverse=True):\n",
    "    bar = \"‚ñà\" * int(score * 50)\n",
    "    print(f\"{name:45s} {score:.4f} {bar}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(f\"üéØ Best Match: {best_match}\")\n",
    "print(f\"   Similarity: {similarities[best_match]:.4f}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a701fbe-47b1-4362-9c3f-05b229aa606e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('Alitibacter langaaensis (NR_118751.1)', np.float32(0.9976617)), ('Alitibacter langaaensis (NR_042885.1)', np.float32(0.997679)), ('Roseovarius maritimus (NR_200035.1)', np.float32(0.9997591))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities.items()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
