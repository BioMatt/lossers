{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5c10a76-09f2-431a-b169-4e56e5664dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Core libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\" # Get rid of warnings\n",
    "\n",
    "# Transformers and PEFT\n",
    "from transformers import AutoTokenizer, AutoModel, BertConfig\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "# Data processing and visualization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Utilities\n",
    "import gc\n",
    "from tqdm.auto import tqdm \n",
    "\n",
    "# Set style for prettier plots\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "print(\"âœ“ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31316e20-81b0-4ff5-96b2-5a4eb126aa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = BertConfig.from_pretrained(\"zhihan1996/DNABERT-2-117M\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"zhihan1996/DNABERT-2-117M\", trust_remote_code=True)\n",
    "model = AutoModel.from_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e9973e8-123c-40e5-8542-012ed602fb3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                genus        species  \\\n",
       "0      Kitasatospora        hibisci   \n",
       "1     Peterkaempfera      podocarpi   \n",
       "2       Streptomyces       citrinus   \n",
       "3            Dickeya       ananatis   \n",
       "4     Microbacterium       wangruii   \n",
       "...              ...            ...   \n",
       "6774     Selenomonas    ruminantium   \n",
       "6775      Nonomuraea  roseoviolacea   \n",
       "6776        Listeria       ivanovii   \n",
       "6777    Streptomyces          albus   \n",
       "6778   Mycobacterium          avium   \n",
       "\n",
       "                                               sequence   identifier  \\\n",
       "0     TTCACGGAGAGTTTGATCCTGGCTCAGGACGAACGCTGGCGGCGTG...  NR_200017.1   \n",
       "1     TTCACGGAGAGTTTGATCCTGGCTCAGGACGAACGCTGGCGGCGTG...  NR_200001.1   \n",
       "2     AGAGTTTGATCCTGGCTCAGGACGAACGCTGGCGGCGTGCTTAACA...  NR_199987.1   \n",
       "3     AAATTGAAGAGTTTGATCATGGCTCAGATTGAACGCTGGCGGCAGG...  NR_199979.1   \n",
       "4     AGAGTTTGATCATGGCTCAGGATGAACGCTGGCGGCGTGCTTAACA...  NR_199966.1   \n",
       "...                                                 ...          ...   \n",
       "6774  ATGCAAGTCGAACGAGGTAATTGAAAGCTTGCTTTTGAGAACCGAG...  NR_036912.1   \n",
       "6775  TCGAGCGGCGAACGGGTGAGTAACACGTGAGCAACCTGCCCCTGAC...  NR_036884.1   \n",
       "6776  AATACATGCAAGTCGAACGAACGGAGGAAGAGCTTGCTCTTCCAAA...  NR_036809.1   \n",
       "6777  AACGCTGGCGGCGTGCTTAACACATGCAAGTCGAACGATGAACCCG...  NR_025615.1   \n",
       "6778  GACGAACGCTGGCGGCGTGCTTAACACATGCAAGTCGAACGGAAAG...  NR_025584.1   \n",
       "\n",
       "            is_complete                 full_name  length  genus_label  \\\n",
       "0     complete sequence     Kitasatospora_hibisci    1517           99   \n",
       "1     complete sequence  Peterkaempfera_podocarpi    1516          166   \n",
       "2      partial sequence     Streptomyces_citrinus    1489          205   \n",
       "3     complete sequence          Dickeya_ananatis    1542           63   \n",
       "4      partial sequence   Microbacterium_wangruii    1487          130   \n",
       "...                 ...                       ...     ...          ...   \n",
       "6774   partial sequence   Selenomonas_ruminantium    1455          190   \n",
       "6775   partial sequence  Nonomuraea_roseoviolacea    1403          150   \n",
       "6776   partial sequence         Listeria_ivanovii    1418          115   \n",
       "6777   partial sequence        Streptomyces_albus    1499          205   \n",
       "6778   partial sequence       Mycobacterium_avium    1472          134   \n",
       "\n",
       "      species_label  \n",
       "0               905  \n",
       "1              1570  \n",
       "2               468  \n",
       "3               130  \n",
       "4              2148  \n",
       "...             ...  \n",
       "6774           1739  \n",
       "6775           1717  \n",
       "6776            995  \n",
       "6777             82  \n",
       "6778            238  \n",
       "\n",
       "[6779 rows x 9 columns]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the new sequence data and run head to see the overall data structure\n",
    "data_in = pd.read_csv(\"data/sequence-cleaner.tsv\", sep='\\t') \n",
    "data_in.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71b93154-30bd-411a-a82b-e6dd4026314b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 115, 174, 222, 23, 177, 143, 33, 166, 403, 247, 123, 150, 527, 2759, 2834, 52, 919, 72, 103, 254, 30, 841, 72, 61, 68, 1695, 328, 54, 205, 3358, 1016, 519, 45, 72, 1200, 137, 1339, 252, 64, 209, 266, 788, 103, 45, 241, 745, 111, 914, 36, 118, 2139, 1587, 316, 97, 679, 628, 76, 1138, 3924, 1834, 136, 2063, 2553, 229, 201, 2369, 100, 72, 755, 78, 1527, 71, 148, 30, 200, 43, 763, 97, 409, 876, 111, 405, 169, 1419, 117, 2275, 64, 72, 31, 120, 559, 607, 200, 25, 1818, 61, 72, 1392, 151, 706, 443, 79, 37, 123, 619, 36, 247, 137, 194, 351, 93, 764, 90, 57, 110, 354, 120, 212, 16, 522, 72, 74, 685, 41, 33, 964, 1220, 15, 150, 102, 15, 220, 51, 93, 1527, 253, 37, 2548, 522, 329, 16, 482, 3434, 315, 103, 265, 159, 113, 591, 57, 140, 103, 19, 259, 174, 304, 229, 3810, 118, 622, 1538, 577, 117, 841, 203, 24, 113, 205, 35, 553, 169, 120, 134, 200, 681, 48, 1138, 3154, 270, 41, 103, 1078, 233, 159, 84, 31, 102, 1149, 282, 1435, 3274, 280, 386, 482, 846, 599, 159, 801, 708, 1788, 540, 10, 93, 547, 118, 317, 292, 76, 269, 100, 70, 13, 128, 270, 1057, 99, 169, 232, 2343, 1319, 588, 2283, 2184, 67, 239, 30, 1518, 742, 15, 153, 90, 547, 93, 1818, 232, 535, 48, 89, 405, 679, 288, 2574, 203, 251, 2684, 56, 40, 1221, 885, 987, 3682, 22, 224, 102, 243, 47, 905, 44, 123, 37, 238, 41, 138, 49, 905, 499, 13, 1493, 174, 841, 26, 175, 36, 136, 638, 1598, 92, 1562, 40, 158, 1918, 793, 31, 105, 68, 704, 254, 266, 3019, 1092, 134, 716, 184, 2146, 1002, 397, 397, 409, 41, 380, 140, 166, 36, 103, 36, 615, 424, 345, 1036, 41, 2620, 1029, 1245, 117, 166, 41, 4060, 138, 36, 1591, 57, 103, 2555, 254, 1746, 8, 2]\n"
     ]
    }
   ],
   "source": [
    "# Convert the new sequences to input tokens, view the first element\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"zhihan1996/DNABERT-2-117M\", trust_remote_code=True)\n",
    "inputs = tokenizer(data_in.sequence.to_list())[\"input_ids\"]\n",
    "print(inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb5d480c-bc7c-4a53-af57-4f096a1deedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Random seeds set for reproducibility\n"
     ]
    }
   ],
   "source": [
    "# Set all random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"âœ“ Random seeds set for reproducibility\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58a1f380-a9fc-4bdf-9c71-e61d4272d1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the train-val-test splits\n",
    "# Configuration\n",
    "prop_train = 0.8\n",
    "prop_val = 0.1\n",
    "prop_test = 0.1\n",
    "SEED = 42\n",
    "\n",
    "# Create random splits\n",
    "rng = np.random.default_rng(SEED)\n",
    "random_idxs = rng.permutation(len(data_in))\n",
    "\n",
    "# Calculate split sizes\n",
    "n_total = len(data_in)\n",
    "n_train = int(prop_train * n_total)\n",
    "n_val = int(prop_val * n_total)\n",
    "\n",
    "train_df = data_in.iloc[random_idxs[:n_train]]\n",
    "val_df = data_in.iloc[random_idxs[n_train:n_train + n_val]]\n",
    "test_df = data_in.iloc[random_idxs[n_train + n_val:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07e15da4-24e8-4722-87b6-173918eb9247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "âœ“ Label encoding complete:\n",
      "  Number of unique species: 222\n",
      "  Example: 'Acetobacter' -> 0\n"
     ]
    }
   ],
   "source": [
    "# Training configuration\n",
    "BATCH_SIZE = 128  \n",
    "LEARNING_RATE = 2e-4\n",
    "NUM_WORKERS = 8\n",
    "NUM_EPOCHS = 40\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# =============================================================================\n",
    "# Step 1: Create Label Encodings for Species\n",
    "# =============================================================================\n",
    "\n",
    "# Encode species names as integers\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(data_in['genus'])\n",
    "\n",
    "# Add encoded labels to dataframes\n",
    "train_df = train_df.copy()\n",
    "val_df = val_df.copy()\n",
    "test_df = test_df.copy()\n",
    "\n",
    "train_df['genus_encoded'] = label_encoder.transform(train_df['genus'])\n",
    "val_df['genus_encoded'] = label_encoder.transform(val_df['genus'])\n",
    "test_df['genus_encoded'] = label_encoder.transform(test_df['genus'])\n",
    "\n",
    "num_classes = len(label_encoder.classes_)\n",
    "print(f\"\\nâœ“ Label encoding complete:\")\n",
    "print(f\"  Number of unique species: {num_classes}\")\n",
    "print(f\"  Example: '{label_encoder.classes_[0]}' -> {0}\")\n",
    "\n",
    "# =============================================================================\n",
    "# Step 2: Update Dataset Class for Classification\n",
    "# =============================================================================\n",
    "class SequenceClassificationDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset class for species classification with integer labels.\n",
    "    \"\"\"\n",
    "    def __init__(self, df, tokenizer, max_length=512):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        sequence = row[\"sequence\"]\n",
    "        label = torch.tensor(row[\"genus_encoded\"], dtype=torch.long)  # Long for classification\n",
    "\n",
    "        # Tokenize sequence\n",
    "        inputs = self.tokenizer(\n",
    "            sequence,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_length,\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        # Remove batch dimension\n",
    "        inputs = {k: v.squeeze(0) for k, v in inputs.items()}\n",
    "        return inputs, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dae46bbc-4aa0-406a-b095-60a5dd778746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Classification Model with LoRA\n",
    "class DNABERTClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Combines LoRA-adapted DNABERT with classification head.\n",
    "    \"\"\"\n",
    "    def __init__(self, base_model, num_classes, hidden_size=768):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model  # LoRA-wrapped DNABERT\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.classifier = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask=None, **kwargs):\n",
    "        # Get embeddings from DNABERT\n",
    "        outputs = self.base_model(\n",
    "            input_ids=input_ids, \n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        \n",
    "        # Use [CLS] token representation (first token)\n",
    "        cls_output = outputs.last_hidden_state[:, 0, :]\n",
    "        \n",
    "        # Apply dropout and classification head\n",
    "        cls_output = self.dropout(cls_output)\n",
    "        logits = self.classifier(cls_output)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a3eae49-0ba8-4f45-9c91-3d88be5e76cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Applying LoRA adapters to model...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Configure LoRA\n",
    "lora_config = LoraConfig(\n",
    "    r=8,                              # Rank (lower = fewer params)\n",
    "    lora_alpha=32,                    # Scaling factor\n",
    "    target_modules=[\"query\", \"value\"], # Adapt attention layers\n",
    "    lora_dropout=0.1,                 # Regularization\n",
    "    bias=\"none\",                      # Don't adapt bias terms\n",
    ")\n",
    "\n",
    "# Apply LoRA to the model\n",
    "print(\"ðŸ”„ Applying LoRA adapters to model...\\n\")\n",
    "ft_model = get_peft_model(model, lora_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2106c6a-8769-432f-965f-540e4c3ba8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create DataLoaders\n",
    "train_dataset = SequenceClassificationDataset(train_df, tokenizer)\n",
    "val_dataset = SequenceClassificationDataset(val_df, tokenizer)\n",
    "test_dataset = SequenceClassificationDataset(test_df, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f353966b-99a0-4e99-9f5d-e14711344fd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNABERTClassifier(\n",
       "  (base_model): PeftModel(\n",
       "    (base_model): LoraModel(\n",
       "      (model): BertModel(\n",
       "        (embeddings): BertEmbeddings(\n",
       "          (word_embeddings): Embedding(4096, 768, padding_idx=0)\n",
       "          (position_embeddings): Embedding(512, 768)\n",
       "          (token_type_embeddings): Embedding(2, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder): BertEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-11): 12 x BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSdpaSelfAttention(\n",
       "                  (query): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (pooler): BertPooler(\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (activation): Tanh()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=222, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try loading the model\n",
    "loaded_model = DNABERTClassifier(\n",
    "    base_model=ft_model,  # LoRA-adapted model\n",
    "    num_classes=num_classes,\n",
    "    hidden_size=768  # DNABERT-2-117M hidden size\n",
    ").to(device)\n",
    "loaded_model.load_state_dict(torch.load('best_model_cleanerfile.pt', weights_only=False))\n",
    "loaded_model.to(device)\n",
    "loaded_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4bbddae2-6848-4d7c-b9ba-0d4e924097f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([1, 222])\n"
     ]
    }
   ],
   "source": [
    "# Test that the model loading worked\n",
    "with torch.no_grad():\n",
    "    dummy_input = torch.randint(0, 4096, (1, 100)).to(device)  # batch_size=1, seq_len=100\n",
    "    output = loaded_model(dummy_input)\n",
    "    print(f\"Output shape: {output.shape}\")  # Should be [1, 222]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b7f2f95-692d-40e5-adb9-929e221fc767",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_v2(model, loader, device):\n",
    "    \"\"\"Evaluate model on validation/test set.\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(loader, desc=\"Evaluating\"):\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            logits = model(**inputs)\n",
    "        \n",
    "    \n",
    "    return logits, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa641013-4348-45fa-937f-83221a767e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE_V2 = 10000\n",
    "\n",
    "val_loader_v2 = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=BATCH_SIZE_V2, \n",
    "    shuffle=False, \n",
    "    num_workers=NUM_WORKERS\n",
    ")\n",
    "test_loader_v2 = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=BATCH_SIZE_V2, \n",
    "    shuffle=False, \n",
    "    num_workers=NUM_WORKERS\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a5cb6ec9-9f49-4407-99d2-380fc017061e",
   "metadata": {},
   "source": [
    "our_results = predict_v2(loaded_model, test_loader_v2, device)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5f012b9a-b160-40f1-88de-89a290478f91",
   "metadata": {},
   "source": [
    "y = our_results[1].detach().cpu().numpy()\n",
    "y_hat_softmax = our_results[0].detach().cpu().numpy()\n",
    "y_hat = np.argmax(y_hat_softmax, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3f0fdd3-5d74-4322-9588-3eaa72e25123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Getting predictions on all splits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.53s/it]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Predictions complete\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# GET PREDICTIONS\n",
    "# ============================================================\n",
    "print(\"\\nðŸ“Š Getting predictions on all splits...\")\n",
    "\n",
    "our_results_val = predict_v2(loaded_model, val_loader_v2, device)\n",
    "our_results_test = predict_v2(loaded_model, test_loader_v2, device)\n",
    "\n",
    "y_val_np = our_results_val[0].cpu().numpy()\n",
    "y_test_np = our_results_test[0].cpu().numpy()\n",
    "\n",
    "print(\"âœ“ Predictions complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0cfb93a-f744-4961-a3b2-f334e3f4ebdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(4.6192117)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_conformity_scores = 1 - y_val_np\n",
    "\n",
    "# 4. Determine the confidence threshold (q-hat)\n",
    "alpha = 0.1 # For 90% coverage\n",
    "n = len(non_conformity_scores)\n",
    "# Finite sample correction: use (n+1) * (1 - alpha) quantile\n",
    "q_hat = np.quantile(non_conformity_scores, np.ceil((n + 1) * (1 - alpha)) / (n + 1))\n",
    "q_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ff00dd4-0128-45d2-89fd-b92b6f327c74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.4990654 ,  0.10947317,  4.6689196 , ...,  5.7750206 ,\n",
       "         5.4592943 ,  5.110993  ],\n",
       "       [ 2.1357875 , -1.1816387 ,  1.7165121 , ..., -1.6634157 ,\n",
       "        -3.385942  , -3.2930603 ],\n",
       "       [-0.6866298 , -1.3679585 ,  5.6655183 , ...,  5.8954043 ,\n",
       "         5.654723  ,  7.4437995 ],\n",
       "       ...,\n",
       "       [-1.1962118 , -0.51744676,  5.3866787 , ...,  6.6428394 ,\n",
       "         6.138448  ,  7.048522  ],\n",
       "       [ 4.7466607 , -0.52846634,  0.11334682, ..., -0.9931381 ,\n",
       "         2.4468029 , -0.761508  ],\n",
       "       [ 1.0740868 ,  2.9336562 ,  1.7209278 , ...,  1.9586672 ,\n",
       "        -3.701559  , -4.051042  ]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_conformity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1a515fb-9210-496d-a44d-9c92cec22814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train_np = our_results_train[0].cpu().numpy().ravel()\n",
    "y_val_true = our_results_val[1].cpu().numpy()\n",
    "y_test_true = our_results_test[1].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ce71ffa-51ca-4372-90d7-3026e51f9aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_calib = y_val_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d112202-1057-4546-898a-dc2e2e100398",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ee95d46-9877-4fcf-84a0-c728410ab4f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1270163e-08, 5.5930894e-07, 5.8547638e-09, ..., 1.9370257e-09,\n",
       "        2.6561586e-09, 3.7628696e-09],\n",
       "       [5.2201085e-06, 1.4401895e-04, 7.9390566e-06, ..., 2.3315936e-04,\n",
       "        1.3053784e-03, 1.1895930e-03],\n",
       "       [3.4750263e-07, 6.8683909e-07, 6.0569677e-10, ..., 4.8130078e-10,\n",
       "        6.1226990e-10, 1.0231920e-10],\n",
       "       ...,\n",
       "       [7.2219501e-07, 3.6632827e-07, 9.9940478e-10, ..., 2.8457567e-10,\n",
       "        4.7125059e-10, 1.8967605e-10],\n",
       "       [2.6007714e-07, 5.0823019e-05, 2.6750045e-05, ..., 8.0884449e-05,\n",
       "        2.5936861e-06, 6.4160718e-05],\n",
       "       [3.3718930e-05, 5.2513792e-06, 1.7658520e-05, ..., 1.3922131e-05,\n",
       "        3.9986237e-03, 5.6713847e-03]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(y_val_np,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b8a8b2e-dd69-4d35-8662-d291bb71d6ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(0.9999945)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_calib = softmax(y_val_np)\n",
    "\n",
    "# Get the probability of the true class for each calibration sample\n",
    "prob_true_class = predictions_calib[np.arange(len(y_calib)), y_calib]\n",
    "# Non-conformity score is 1 - P(true class)\n",
    "non_conformity_scores = 1 - prob_true_class\n",
    "\n",
    "# 4. Determine the confidence threshold (q-hat)\n",
    "alpha = 0.1 # For 90% coverage\n",
    "n = len(non_conformity_scores)\n",
    "# Finite sample correction: use (n+1) * (1 - alpha) quantile\n",
    "q_hat = np.quantile(non_conformity_scores, np.ceil((n + 1) * (1 - alpha)) / (n + 1))\n",
    "q_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ef958a3f-0970-4ee7-a5fa-959c2178443b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test = softmax(y_test_np)\n",
    "prediction_sets = (1 - predictions_test) <= q_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "34ba19ea-e4ae-490f-8d4f-bee2de91c513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       ...,\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "86eccad8-d786-4b1c-892b-1fe5a15dc39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "conformal_set_sizes = np.sum(prediction_sets, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "29e75496-e877-4e81-a16f-efd4e2fe50c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 22.,   0., 402.,   0.,   0., 197.,   0.,  50.,   0.,   8.]),\n",
       " array([0. , 0.4, 0.8, 1.2, 1.6, 2. , 2.4, 2.8, 3.2, 3.6, 4. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(conformal_set_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2e99bdc4-7fa9-4344-9226-89b29038f1dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([205, 174,  73, 146, 171, 176, 205, 217,  75, 133,  93, 101, 208,\n",
       "        76, 110,  67, 141, 205,  28, 152, 154, 152, 153, 119,  82,  73,\n",
       "       155,  24, 140, 205,  30, 130,  92,  10, 120, 176,  68, 146, 146,\n",
       "       205, 157, 138, 138,  59, 205,   5,   5,  56, 143, 146, 176, 205,\n",
       "       104,  67, 128,   8, 204,  32,  82,  58,  67, 205, 133, 179, 146,\n",
       "       185, 105, 205,  18, 136,  36,  18, 204, 149,  61,  90,  64, 205,\n",
       "       195,  55,  76, 153, 136, 205,  39, 140,  41, 204, 190,  82, 214,\n",
       "       196,  60, 113,  62,  27,   2, 205,  88, 205,   7, 137,  29,   3,\n",
       "        67, 138, 205,  67,  89, 130, 112, 176,  54, 101, 199, 196,  43,\n",
       "       107, 170, 205,  27, 134,  83,  61, 176, 153, 205, 130, 153,  41,\n",
       "       205, 146, 148, 205, 205,  11, 146, 158, 121,  99,  86,  54,  23,\n",
       "        85,  48,  79, 136, 202, 205, 205, 118,  92, 183,  27,  12, 141,\n",
       "       200,  56, 176, 205, 182, 107,  56, 120, 176,  75, 175, 205, 205,\n",
       "       146,  57, 148, 101, 125, 177,   7, 108, 154,  67, 205, 176, 217,\n",
       "       205,  10, 117, 136,  54,  37, 205,  67, 127, 205, 205, 182, 205,\n",
       "       171, 205, 195,  26, 158, 217,  75,  67,   9, 200, 138, 155,  84,\n",
       "       205, 107, 173, 205, 205,  16, 177,  54,  74,  56, 205, 205,   4,\n",
       "       197,  79,  42,  40,  19,  42,  90, 205, 217, 136, 204, 183, 176,\n",
       "       205, 104, 207, 193, 128, 121,  90,  82, 171,  88, 146, 102,  27,\n",
       "       164,  26, 122,  27, 107, 205, 178,  10, 205, 205, 101, 134, 196,\n",
       "       211,  82, 205, 176, 104,  54,  41, 143,   4, 134, 205, 112,  67,\n",
       "       200, 205,  95, 217, 205,  56,   9,  12,  27,  47, 146, 128,  59,\n",
       "       217, 177,  11, 153, 101, 203, 205, 191, 211, 153,   8, 204, 104,\n",
       "       185,  67, 217, 123,  42,  79,  90,  67, 205,  82, 196, 205,  90,\n",
       "       207,  35, 183,  90,  29,  19,  93, 217, 192, 217, 158,  33,  99,\n",
       "       134, 204,  39, 205, 217, 192,  82,  54, 219, 217, 139,  71,  90,\n",
       "        68,   4, 196,   9, 111, 194, 205, 217,  88, 146, 185,  41, 121,\n",
       "        38,  67, 177,   9,  26, 205,   0,   4, 146,  73, 187, 219, 205,\n",
       "        96, 191, 205, 133, 162, 134, 205,   9,  71,  10, 153,  13,  13,\n",
       "       217, 168, 200, 219, 211,  48,  67,  44,  51, 217, 192, 148, 153,\n",
       "       104,  90, 105, 216, 205, 208,  30, 123, 205, 205, 198, 197,  61,\n",
       "       114, 204, 134, 176, 145, 173, 107, 126, 217, 176,  54, 183, 196,\n",
       "       217, 205, 217,  54, 217, 139,  82, 124, 176,  54,  55, 179,   9,\n",
       "       158,  67,  99, 153, 146,  85, 104, 205, 137, 190, 168, 134, 176,\n",
       "       179,  54, 146, 101,  39, 179, 205, 205, 146, 205,   2,  36,  35,\n",
       "        54, 136, 205, 100, 171,  27,  68, 187, 146,  10,  88,  92,  26,\n",
       "        36,  60,   9, 205,  61, 152, 192,  28,  44, 182, 201, 205, 155,\n",
       "       182, 146, 205, 146, 180, 205,  85, 100,  42, 185, 170, 131, 205,\n",
       "        89, 102,  38, 112, 202, 205, 205, 158, 183, 175,  71,  48, 192,\n",
       "        31,   6,  99, 146, 205, 190, 156,  84, 196,  64, 161,  90,  28,\n",
       "       120,  20, 162, 218,  75, 170, 152, 196, 161,  54, 205, 205, 153,\n",
       "       187, 130, 106, 134, 146, 120, 193, 205, 134, 148,  87, 162, 176,\n",
       "       205,  82,  95, 204,  27,  98, 171, 205, 107, 196, 146, 205, 204,\n",
       "       205, 170, 155, 199, 153,   7, 179,  76,  51, 126, 204, 154, 160,\n",
       "        31,  70, 155, 205, 146,  48, 154, 112, 118,  41, 205, 146, 129,\n",
       "         4, 145,  58, 202, 176,  40, 205, 146, 162, 205, 138, 144, 217,\n",
       "       205,   9, 178,  54, 205,  56,  50, 176,  99,   7, 130,  66,  75,\n",
       "       110, 168,  20,   7,   5, 152, 192, 205, 112,  49, 221,  39,  54,\n",
       "       196, 176, 153,  39, 205, 205, 198,  77,  86,  21,  99, 153, 205,\n",
       "        13,  67,  28, 200, 100, 205,   8, 175, 115, 130, 192,  24,  99,\n",
       "       126, 126, 210,  16, 205,  23, 205, 133, 205, 171, 171,   9,  94,\n",
       "       201, 109, 109, 217,   3, 146, 205, 214, 207,  38, 205,  48, 107,\n",
       "       205, 205,  75])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_test_np, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d117eff7-e2a5-4933-8555-45a64fec12db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([205, 174,  73, 146, 171, 176, 205, 217,  75, 133])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_true[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "79d28760-4537-4ecf-80a1-7fbf9e304e9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.1426262e-09, 3.5436123e-09, 1.1051833e-11, ..., 1.1122401e-11,\n",
       "        1.8829551e-11, 3.3680996e-12],\n",
       "       [1.5648568e-09, 1.3144143e-11, 3.7435841e-10, ..., 4.2698386e-10,\n",
       "        4.1964254e-09, 3.8093681e-10],\n",
       "       [3.3548266e-09, 1.7350410e-10, 1.1795048e-09, ..., 2.0451345e-10,\n",
       "        1.8524293e-08, 1.9438022e-10],\n",
       "       ...,\n",
       "       [5.4121205e-09, 7.9545659e-09, 9.6192490e-12, ..., 6.6953279e-12,\n",
       "        1.3650057e-11, 3.0081718e-12],\n",
       "       [1.5927077e-09, 5.7479848e-09, 7.0487023e-12, ..., 5.5768229e-12,\n",
       "        9.2621640e-12, 9.1245171e-12],\n",
       "       [1.3007515e-08, 3.5309000e-10, 2.8793257e-10, ..., 2.6208807e-10,\n",
       "        1.7380858e-09, 6.1343444e-11]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2609df-ee40-42c5-9a35-4b1d5c2d6794",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c439e5-35f4-4c0e-928a-48262a0ca809",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab9232d-ef2e-434c-a380-1c5ef3f27eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_np = our_results_val[0].cpu().numpy()\n",
    "y_test_np = our_results_test[0].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04074d4c-02fb-4101-a906-821a18dd1294",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_true = our_results_val[1].cpu().numpy()\n",
    "y_test_true = our_results_test[1].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7a0e53e9-0e65-4962-84f5-3065e479284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('y_val_pred_proba.npy', y_val_np)\n",
    "np.save('y_test_pred_proba.npy', y_test_np)\n",
    "np.save('y_val_true.npy', y_val_true)\n",
    "np.save('y_test_true.npy', y_test_true)\n",
    "np.save('conformity_sets.npy', prediction_sets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
